{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 2s 0us/step\n",
      "X_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               4194816   \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 4,200,842\n",
      "Trainable params: 4,200,842\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "40000/40000 [==============================] - 50s 1ms/step - loss: 1.6917 - accuracy: 0.3990 - val_loss: 1.5287 - val_accuracy: 0.4387\n",
      "Epoch 2/20\n",
      "40000/40000 [==============================] - 50s 1ms/step - loss: 1.3384 - accuracy: 0.5254 - val_loss: 1.2259 - val_accuracy: 0.5744\n",
      "Epoch 3/20\n",
      "40000/40000 [==============================] - 54s 1ms/step - loss: 1.2118 - accuracy: 0.5715 - val_loss: 1.1747 - val_accuracy: 0.5966\n",
      "Epoch 4/20\n",
      "40000/40000 [==============================] - 56s 1ms/step - loss: 1.1192 - accuracy: 0.6068 - val_loss: 1.1035 - val_accuracy: 0.6140\n",
      "Epoch 5/20\n",
      "40000/40000 [==============================] - 51s 1ms/step - loss: 1.0404 - accuracy: 0.6338 - val_loss: 1.1130 - val_accuracy: 0.6101\n",
      "Epoch 6/20\n",
      "40000/40000 [==============================] - 51s 1ms/step - loss: 0.9863 - accuracy: 0.6542 - val_loss: 1.0748 - val_accuracy: 0.6264\n",
      "Epoch 7/20\n",
      "40000/40000 [==============================] - 51s 1ms/step - loss: 0.9220 - accuracy: 0.6791 - val_loss: 1.1108 - val_accuracy: 0.6226\n",
      "Epoch 8/20\n",
      "40000/40000 [==============================] - 51s 1ms/step - loss: 0.8784 - accuracy: 0.6963 - val_loss: 1.0649 - val_accuracy: 0.6358\n",
      "Epoch 9/20\n",
      "40000/40000 [==============================] - 55s 1ms/step - loss: 0.8325 - accuracy: 0.7080 - val_loss: 1.0992 - val_accuracy: 0.6379\n",
      "Epoch 10/20\n",
      "40000/40000 [==============================] - 54s 1ms/step - loss: 0.7947 - accuracy: 0.7234 - val_loss: 1.0729 - val_accuracy: 0.6384\n",
      "Epoch 11/20\n",
      "40000/40000 [==============================] - 51s 1ms/step - loss: 0.7622 - accuracy: 0.7365 - val_loss: 0.9707 - val_accuracy: 0.6747\n",
      "Epoch 12/20\n",
      "40000/40000 [==============================] - 51s 1ms/step - loss: 0.7229 - accuracy: 0.7520 - val_loss: 1.0557 - val_accuracy: 0.6541\n",
      "Epoch 13/20\n",
      "40000/40000 [==============================] - 50s 1ms/step - loss: 0.6960 - accuracy: 0.7591 - val_loss: 0.9826 - val_accuracy: 0.6776\n",
      "Epoch 14/20\n",
      "40000/40000 [==============================] - 51s 1ms/step - loss: 0.6684 - accuracy: 0.7706 - val_loss: 1.0546 - val_accuracy: 0.6658\n",
      "Epoch 15/20\n",
      "40000/40000 [==============================] - 56s 1ms/step - loss: 0.6317 - accuracy: 0.7823 - val_loss: 1.0187 - val_accuracy: 0.6772\n",
      "Epoch 16/20\n",
      "40000/40000 [==============================] - 52s 1ms/step - loss: 0.6104 - accuracy: 0.7910 - val_loss: 1.0202 - val_accuracy: 0.6750\n",
      "Epoch 17/20\n",
      "40000/40000 [==============================] - 50s 1ms/step - loss: 0.5791 - accuracy: 0.8024 - val_loss: 1.0059 - val_accuracy: 0.6840\n",
      "Epoch 18/20\n",
      "40000/40000 [==============================] - 51s 1ms/step - loss: 0.5744 - accuracy: 0.8037 - val_loss: 1.0297 - val_accuracy: 0.6739\n",
      "Epoch 19/20\n",
      "40000/40000 [==============================] - 51s 1ms/step - loss: 0.5519 - accuracy: 0.8112 - val_loss: 1.0606 - val_accuracy: 0.6824\n",
      "Epoch 20/20\n",
      "40000/40000 [==============================] - 52s 1ms/step - loss: 0.5364 - accuracy: 0.8175 - val_loss: 1.0776 - val_accuracy: 0.6713\n",
      "10000/10000 [==============================] - 6s 610us/step\n",
      "Test score: 1.0649443365097047\n",
      "Test accuracy: 0.6689000129699707\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "import matplotlib.pyplot as plt\n",
    "import ssl\n",
    "\n",
    "ssl._create_default_https_context=ssl._create_unverified_context\n",
    "\n",
    "\n",
    "NUM_TO_AUGMENT=5 \n",
    "\n",
    "# CIFAR_10 is a set of 60K images 32x32 pixels on 3 channels\n",
    "IMG_CHANNELS = 3\n",
    "IMG_ROWS = 32\n",
    "IMG_COLS = 32\n",
    "#constant\n",
    "BATCH_SIZE = 128\n",
    "NB_EPOCH = 20\n",
    "NB_CLASSES = 10\n",
    "VERBOSE = 1\n",
    "VALIDATION_SPLIT = 0.2\n",
    "OPTIM = RMSprop()\n",
    "\n",
    "#load dataset\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# convert to categorical\n",
    "Y_train = np_utils.to_categorical(y_train, NB_CLASSES)\n",
    "Y_test = np_utils.to_categorical(y_test, NB_CLASSES)\n",
    "# float and normalization\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# network\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "input_shape=(IMG_ROWS, IMG_COLS, IMG_CHANNELS)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(NB_CLASSES))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    "\n",
    "# train\n",
    "model.compile(loss='categorical_crossentropy', optimizer=OPTIM,\n",
    "metrics=['accuracy'])\n",
    "model.fit(X_train, Y_train, batch_size=BATCH_SIZE,\n",
    "epochs=NB_EPOCH, validation_split=VALIDATION_SPLIT,\n",
    "verbose=VERBOSE)\n",
    "score = model.evaluate(X_test, Y_test,\n",
    "batch_size=BATCH_SIZE, verbose=VERBOSE)\n",
    "print(\"Test score:\", score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "#save model\n",
    "model_json = model.to_json()\n",
    "open('cifar10_architecture.json', 'w').write(model_json)\n",
    "# And the weights learned by our deep network on the training set\n",
    "model.save_weights('cifar10_weights.h5', overwrite=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   This type of algorithm can lead to some ethical problems when used for facial recognition. Racial bias can occur due to testing innacuracies. Data privacy is a major concern of this technology. Saving facial records can be seen as a breachof privacy. The European Commision banned facial recognition technology being used in public in 2020. This is due to a concern about if the facial data gets leaked or stolen. There is concerns about peoples' facial data being stolen without their knowing. Many concerns of this technology can be solved by informing people of when the tech is being used and then ask for the person's concent to have their face recorded.\n",
    "\n",
    "Source:\n",
    "   Gangarapu, K. R. (2022, January 25). Ethics of Facial Recognition: Key Issues and Solutions. Learn.g2.com. https://learn.g2.com/ethics-of-facial-recognition"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
